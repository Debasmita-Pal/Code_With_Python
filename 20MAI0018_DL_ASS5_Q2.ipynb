{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20MAI0018_DL_ASS5_Q2.ipynb",
      "provenance": [],
      "mount_file_id": "1j2lO2NL-yWJfSy2odDs7SggPevOqzwcg",
      "authorship_tag": "ABX9TyNC5eN/z5Vbhcy0fnta1asu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Debasmita-Pal/Code_With_Python/blob/main/20MAI0018_DL_ASS5_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8eUFehDNbtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9043ca44-9036-4933-cf29-1059d3584e16"
      },
      "source": [
        "#REG NO: 20MAI0018\n",
        "\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "class RNN():\n",
        "\tdef __init__(self, insize, hsize, outsize, learning_rate=0.1):\n",
        "\n",
        "\t\t# voacb size\n",
        "\t\tself.vocab_size = insize\n",
        "\n",
        "\t\t# [1 x H] hidden state, summarising the contents of past\n",
        "\t\tself.h = np.zeros((1, hsize))\n",
        "\n",
        "\t\t# weights, normally distributed\n",
        "\t\tself.Wxh = np.random.randn(insize, hsize) * 0.01\n",
        "\t\tself.Whh = np.random.randn(hsize, hsize) * 0.01\n",
        "\t\tself.Why = np.random.randn(hsize, outsize) * 0.01\n",
        "\n",
        "\t\t# biases\n",
        "\t\tself.bh = np.zeros((1, hsize))\n",
        "\t\tself.by = np.zeros((1, outsize))\n",
        "\n",
        "\t\tself.lr = learning_rate\n",
        "\n",
        "\tdef train(self, inputs, targets):\n",
        "\t\tx, h, y, p = {}, {}, {}, {}\n",
        "\n",
        "\t\tloss = 0\n",
        "\t\th[-1] = np.copy(self.h)\n",
        "\n",
        "\t\t\n",
        "\t\t# -------- Forward-pass --------\n",
        "\t\t# for each time-step\n",
        "\t\tfor t in range(len(inputs)):\n",
        "\t\t\t# one-hot-encode input\n",
        "\t\t\tx[t] = np.zeros((1, self.vocab_size))\n",
        "\t\t\tx[t][0][inputs[t]] = 1\n",
        "\n",
        "\t\t\t# tanh(x*w1 + h_prev*w1 + b) -- hidden state\n",
        "\t\t\th[t] = np.tanh(np.dot(x[t], self.Wxh) + np.dot(h[t-1], self.Whh) + self.bh)\n",
        "\n",
        "\t\t\t# unnormalized log probabilities for next char\n",
        "\t\t\ty[t] = np.dot(h[t], self.Why) + self.by\n",
        "\n",
        "\t\t\t# probability distribution, softmax loss\n",
        "\t\t\tp[t] = np.exp(y[t]) / np.sum(np.exp(y[t]))\n",
        "\t\t\tloss += -p[t][0][targets[t]]\n",
        "\t\t\n",
        "\t\t# -------- Backward-pass --------\n",
        "\t\t\n",
        "\t\t\n",
        "\n",
        "\t\treturn loss\n",
        "\n",
        "\n",
        "def main():\n",
        "\t# I/O\n",
        "\t# should be simple plain text file\n",
        "\tdata = open('/content/drive/My Drive/paulg.txt').read()\n",
        "\tchars = list(set(data))\n",
        "\n",
        "\tdata_size, vocab_size = len(data), len(chars)\n",
        "\tprint('File has {} characters with {} unique.'.format(data_size, vocab_size))\n",
        "\n",
        "\t# make some dictionaries for encoding and decoding from 1-of-k\n",
        "\tchar_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "\tix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "\t# network arch for RNN\n",
        "\tinsize, outsize = vocab_size, vocab_size\n",
        "\thsize = 100\n",
        "\t\n",
        "\trnn = RNN(insize, hsize, outsize)\n",
        "\n",
        "\ti, n = 0, 0\n",
        "\tseq_length = 10 # number of steps to unroll the RNN for\n",
        "\t\n",
        "\t# while True:\n",
        "\tfor _ in range(1):\n",
        "\t\tinputs = [char_to_ix[ch] for ch in data[i:i+seq_length]]\n",
        "\t\ttargets = [char_to_ix[ch] for ch in data[i+1:i+seq_length+1]]\n",
        "\n",
        "\t\tloss = rnn.train(inputs, targets)\n",
        "\t\tprint(loss)\n",
        "\n",
        "\t\ti += seq_length\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttry:\n",
        "\t\tmain()\n",
        "\texcept KeyboardInterrupt:\n",
        "\t\tprint('\\nKeyboardInterrupt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File has 2378592 characters with 98 unique.\n",
            "-0.10201398051815512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0OK_l_2NbdB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}